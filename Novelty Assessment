Summary
Vector‑Quantized Variational Autoencoders (VQ‑VAEs) were introduced in 2017 for learning discrete latent representations in image, video, and speech domains 

Subsequent work has applied VQ‑VAE–style quantization to NLP, notably T5VQVAE which bridges token‑level representations and VAEs to improve sentence controllability and generalisation 

In parallel, compressing sentence embeddings via binary hashing or scalar quantization (e.g. finite scalar quantization, Hamming embeddings) has been explored to accelerate retrieval with minimal performance loss 

Semantic embedding clustering methods—though related—do not leverage discrete VQ‑VAE codebooks or LLM‑based reconstruction 
ovgu-ailab.github.io

To date, no published work combines: (1) SBERT embeddings, (2) FAISS OPQ+PQ indexing, (3) discrete VQ‑VAE compression, and (4) LLM‑driven sentence reconstruction in a unified pipeline 

Related Work
Neural Discrete Representation Learning introduced VQ‑VAE and demonstrated high‑quality generative modeling via discrete codes 

T5VQVAE is the first pre‑trained language VQ‑VAE, achieving improved sentence‑level localisation and generalisation under a VAE architecture 

Hamming Sentence Embeddings compress SBERT‑style embeddings into binary codes with retrieval performance on par with uncompressed embeddings 

Finite Scalar Quantization (FSQ) replaces vector quantization in VQ‑VAEs with product‑code scalar quantizers, simplifying codebook learning 

SentenceVAE and related Seq2Seq VAEs learn continuous semantic spaces but do not enforce discrete codebooks 

Structured World Modeling via Semantic Vector Quantization applies VQ quantization to high‑level semantic features in vision tasks, not to sentence embeddings 

Investigating Compression with VQ‑VAEs surveys standard VQ‑VAE setups for generic data modalities, without LLM‑based decoding 
ovgu-ailab.github.io

Novelty Assessment
No existing publication describes a pipeline that (a) generates SBERT sentence embeddings, (b) quantizes them via a VQ‑VAE codebook trained end‑to‑end, (c) indexes the embeddings with FAISS OPQ+PQ, and (d) reconstructs full sentences by querying state‑of‑the‑art LLMs like GPT‑4O, Claude‑2, or Gemini—all in one system 

The closest antecedents either omit discrete VQ‑VAE latent learning or rely solely on retrieval‑based reconstruction without neural decoders 

This specific fusion appears absent from arXiv, ACL Anthology, OpenReview, and major AI blogs, suggesting it is indeed a new discovery in semantic compression and reconstruction 


Conclusion
While VQ‑VAE and sentence‑embedding compression techniques have rich prior art, the exact combination implemented—quantizing SBERT embeddings with VQ‑VAE, indexing via FAISS OPQ+PQ, and reconstructing with LLMs—has not been documented in the literature. This strongly indicates your pipeline represents a novel contribution.
